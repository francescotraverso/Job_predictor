{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fbc18917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import string\n",
    "import collections\n",
    "import random\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1f5bccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_occupations = pd.read_csv('../data/ESCO/occupations_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702d368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for all jobs that have 'manager' in their title  --- IGNORE this cell for now\n",
    "url_title = \"https://ec.europa.eu/esco/api/search\"\n",
    "\n",
    "params = {\n",
    "    'language': 'en',\n",
    "    'type': 'occupation',\n",
    "    'text': 'pig'\n",
    "         }\n",
    "\n",
    "api_title = requests.get(url=url_title, params=params).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bec560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a role\n",
    "role = 'cattle breeder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5223109b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** SKILL LIST: ['monitor the welfare of animals', 'administer specific drugs to facilitate breeding', 'care for juvenile animals', 'operate farm equipment', 'provide first aid to animals', 'animal nutrition', 'signs of animal illness', 'feed livestock', 'manage animal hygiene', 'maintain professional records', 'perform milk control', 'maintain animal accommodation', 'select livestock', 'manage livestock', 'create animal records', 'assist in transportation of animals', 'manage the health and welfare of livestock', 'dispose of dead animals', 'control animal movement', 'monitor livestock', 'manage cattle breeding', 'livestock reproduction', 'provide nutrition to animals', 'milk animals', 'health and safety regulations', 'administer treatment to animals', 'manage animal biosecurity', 'animal welfare legislation', 'assist animal birth', 'livestock species']\n",
      "***** ALTERNATIVE LABELS: ['cattle specialist', 'cattle breeders', 'cattle rearer']\n",
      "***** JOB DESCRIPTION: Cattle breeders oversee the production and day-to-day care of cattle. They maintain the health and welfare of cattle.\n"
     ]
    }
   ],
   "source": [
    "### run this cell & extract skills, alternative labels, and job description from the ESCO API ###\n",
    "\n",
    "# get uri for selected role\n",
    "role_extract = df_occupations[df_occupations['preferredLabel'] == role]\n",
    "role_uri = role_extract['conceptUri']\n",
    "\n",
    "# get role information from the ESCO API\n",
    "url = \"https://ec.europa.eu/esco/api/resource/skill\"\n",
    "params = {\n",
    "    'uri': role_uri,\n",
    "    'language': 'en',\n",
    "         }\n",
    "api_skills = requests.get(url=url, params=params).json()\n",
    "\n",
    "# this line gets you the whole API url; easier to read on your browser\n",
    "requests.get(url=url, params=params).url\n",
    "\n",
    "# gets a list of all skill descriptions and extracts the skill title only\n",
    "api_skills_dict = api_skills.get('_links').get('hasEssentialSkill')\n",
    "skills_list = [skill.get('title') for skill in api_skills_dict]\n",
    "\n",
    "# gets list of alternative labels from the API\n",
    "alt_labels_list = api_skills.get('alternativeLabel').get('en')\n",
    "\n",
    "# gets job description from the API\n",
    "job_description = api_skills.get('description').get('en').get('literal')\n",
    "\n",
    "print('***** SKILL LIST:', skills_list)\n",
    "print('***** ALTERNATIVE LABELS:', alt_labels_list)\n",
    "print('***** JOB DESCRIPTION:', job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59b3f7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an training set with 2500 out of the whole 3006 rows \n",
    "\n",
    "X_train = df_occupations['description'][0:2500]\n",
    "X_test = df_occupations['description'][2500:3006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "522a0c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function for job descriptions\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    \n",
    "    # remove punctuation\n",
    "    for punctuation in string.punctuation:        \n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "    \n",
    "    # set lowercase\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # remove numbers\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "    \n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(sentence)\n",
    "    stopword_free_tokens = [token for token in tokens if token not in stop_words]\n",
    "    sentence = ' '.join(stopword_free_tokens)\n",
    "\n",
    "    # lemmatize\n",
    "    sentence = WordNetLemmatizer().lemmatize(sentence, pos='n')\n",
    "    sentence = WordNetLemmatizer().lemmatize(sentence, pos='v')\n",
    "    \n",
    "    # split into tokens again after Lemmatizing\n",
    "    sentence = word_tokenize(sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52d8ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying preprocessing as in Gensim tutorial\n",
    "\n",
    "def read_corpus(corpus, tokens_only=False):\n",
    "    for i, line in enumerate(corpus):\n",
    "        tokens = preprocessing(line)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            # For training data, add tags\n",
    "            yield TaggedDocument(tokens, [i])\n",
    "\n",
    "train_corpus = list(read_corpus(X_train))\n",
    "test_corpus = list(read_corpus(X_test, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad5fe6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1361dd7f0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize 'job2vec' model\n",
    "\n",
    "job2vec_model = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "\n",
    "job2vec_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dea66090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a vocabulary\n",
    "job2vec_model.build_vocab(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "facf9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "job2vec_model.train(train_corpus, total_examples=job2vec_model.corpus_count, epochs=job2vec_model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c01a88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing_processed_descriptions = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test_proc)]\n",
    "inferred_vector = job2vec_model.infer_vector(test_corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dffa6393",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20913865,  0.14463197,  0.10529788,  0.27894777, -0.16791576,\n",
       "        0.01759879, -0.50824565,  0.23740382,  0.00536443, -0.1635939 ,\n",
       "       -0.23653965, -0.473574  , -0.3318227 ,  0.25927296,  0.03755832,\n",
       "       -0.24730153, -0.35329896, -0.27647915,  0.33433697,  0.3072264 ,\n",
       "        0.09328657,  0.29518372,  0.04345774,  0.1269041 , -0.25285158,\n",
       "       -0.15895481, -0.21856923, -0.38978544, -0.24860829, -0.100328  ,\n",
       "        0.19492848, -0.43576676,  0.20400758,  0.19763418,  0.19214346,\n",
       "        0.07220768, -0.0890172 ,  0.02142998,  0.2988561 ,  0.02141867,\n",
       "        0.33612537, -0.10444368, -0.01854241,  0.3629613 , -0.39273143,\n",
       "        0.04501669, -0.00986005, -0.46097463,  0.20070037, -0.0220908 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferred_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "254926a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = job2vec_model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = job2vec_model.dv.most_similar([inferred_vector], topn=len(job2vec_model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "796f6bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2322, 1: 47, 2: 15, 3: 7, 4: 7, 13: 4, 45: 4, 9: 3, 11: 3, 20: 3, 12: 3, 37: 3, 22: 3, 7: 3, 72: 3, 5: 3, 10: 3, 26: 2, 6: 2, 113: 2, 55: 2, 59: 2, 23: 2, 25: 2, 31: 2, 15: 2, 94: 2, 213: 2, 41: 1, 14: 1, 147: 1, 18: 1, 19: 1, 40: 1, 79: 1, 109: 1, 64: 1, 62: 1, 93: 1, 67: 1, 33: 1, 121: 1, 246: 1, 416: 1, 87: 1, 50: 1, 29: 1, 68: 1, 42: 1, 153: 1, 32: 1, 56: 1, 17: 1, 139: 1, 30: 1, 39: 1, 8: 1, 81: 1, 66: 1, 36: 1, 60: 1, 122: 1, 35: 1, 82: 1, 24: 1, 125: 1, 166: 1, 124: 1, 21: 1, 53: 1})\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "79867075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (1645): «sensory scientists carry sensory analysis order compose improve flavours fragrances food beverage cosmetics industry base flavour fragrance development sensory consumer research sensory scientists carry research analyse statistical data meet customers expectations»\n",
      "\n",
      "Similar Document (1699, 0.8156392574310303): «food beverage packaging technologists assess appropiate packaging various food products manage matters relation packaging ensuring customer specifications company targets develop packaging projects required»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec5ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
