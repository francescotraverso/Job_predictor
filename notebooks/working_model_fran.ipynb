{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc18917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pyresparser import ResumeParser\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9c1bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_description(job_description, no_words=100):\n",
    "    return ' '.join(job_description.split()[:no_words:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed5de1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ftraverso/.pyenv/versions/3.8.12/envs/job_predictor-env/lib/python3.8/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.5). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Property Value Analyst, 2017 – present Companies: Fenacam (creditoagricola.pt), Coimbra District Court, private clients and 9 other appraisal companies - Appraisal of flats, houses, stores, warehouses, hotels and lands for investment funds, city courts, private clients and bank mortgage loans for almost every major bank in Portugal. - Property data was gathered daily and treated statistically to produce appraisal reports, fueling the desire to pursue a path in Data Science.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###DECLARE CV PATH###\n",
    "path = '/home/ftraverso/code/francescotraverso/job_predictor/data/cv_directory/CV_Example.pdf'\n",
    "\n",
    "###OPEN RESUME###\n",
    "resume = ResumeParser(path).get_extracted_data()\n",
    "\n",
    "###EXTRACT JOB EXPERIENCE###\n",
    "JD =  \"\"\"\n",
    "Property Value Analyst, 2017 – present\n",
    "Companies: Fenacam (creditoagricola.pt), Coimbra District Court, private clients and 9 other appraisal companies\n",
    "- Appraisal of flats, houses, stores, warehouses, hotels and lands for investment funds, city courts, private clients and \n",
    "bank mortgage loans for almost every major bank in Portugal.\n",
    "- Property data was gathered daily and treated statistically to produce appraisal reports, fueling the desire to pursue a \n",
    "path in Data Science.\n",
    "- Also issued Energy Performance Certificates of flats, houses and shops.\n",
    "- Created the imostudio brand (imostudio.pt) for online business promotion.\n",
    "Cluster and Operations Manager, 2016 – 2018\n",
    "MTD Pure Water (mtd.net)\n",
    "- Coordinated design and setting up of technical solutions for temporary water and wastewater installations for the \n",
    "2016 Olympic Games in Rio de Janeiro and for 3 exhibition centers in Paris.\n",
    "- Responsible for team leadership, planning, equipment requests and liaison with venue managers.\n",
    "- For its delivery in the 2016 Olympics, MTD was awarded Best Operations Team at the Sports Business Awards 2017.\n",
    "Site and Supervision Manager in Civil Engineering, 2006 – 2016\n",
    "Companies: Pengest (pengest.pt), Lena Group (grupolena.pt), Projectual (projectual.pt) and Serrialu (serrialu.com)\n",
    "- Managed and supervised construction projects from 0,5 M€ to 31 M€ in Portugal, Algeria, Angola and France.\n",
    "- Responsible for team leadership, planning, works coordination, invoicing, procurement, contract management,\n",
    "tendering and cost control.\n",
    "- Throughout the projects, data was collected and treated to make decisions and to report financial performance.\n",
    "\"\"\"\n",
    "#\" \".join(resume['experience'])\n",
    "JD = truncate_description(JD, no_words=70)\n",
    "JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03c38a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/skill_packages/ESCO/marketing_skills_esco.csv', newline='') as f:\n",
    "    reader = csv.reader(f)\n",
    "    csv_data = list(reader)\n",
    "    ds_keywords = [item for sublist in csv_data for item in sublist]\n",
    "\n",
    "ds_skills = \" \".join(ds_keywords)\n",
    "#ds_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c00aa9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Property Value Analyst, 2017 – present Companies: Fenacam (creditoagricola.pt), Coimbra District Court, private clients and 9 other appraisal companies - Appraisal of flats, houses, stores, warehouses, hotels and lands for investment funds, city courts, private clients and bank mortgage loans for almost every major bank in Portugal. - Property data was gathered daily and treated statistically to produce appraisal reports, fueling the desire to pursue a path in Data Science.identify customer requirements identify potential markets for companies respond to enquiries identify market niches carry out strategic research analyse external factors of companies use different communication channels plan marketing strategy integrate marketing strategies with the global strategy analyse internal factors of companies use theoretical marketing models maintain relationship with customers conduct research interview define technical requirements market analysis marketing principles marketing mix advertising techniques social media management web strategy assessment channel marketing online ads campaign techniques brand marketing techniques e-commerce systems customer service social media marketing techniques perform business research support managers draft corporate emails manage the handling of promotional materials assist in developing marketing campaigns prepare presentation material marketing management marketing department processes collaborate in the development of marketing strategies persuade clients with alternatives liaise with advertising agencies conduct mobile marketing execute email marketing execute conversion testing implement marketing strategies use content management system software use different communication channels develop inclusive communication material plan marketing campaigns manage brand assets select optimal distribution channel perform brand analysis perform market research stimulate creativity in the team coordinate advertising campaigns'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "### describe your job!!! ###\n",
    "############################\n",
    "\n",
    "describe_your_job = JD + ds_skills\n",
    "\n",
    "##################################\n",
    "### get 'n' job suggeestion!!! ###\n",
    "##################################\n",
    "\n",
    "n_jobs = 10\n",
    "\n",
    "describe_your_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f5bccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2709/608757610.py:3: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_occ_n_skills = pd.read_csv('../data/ESCO/occupations_augmented_with_skills.csv')\n"
     ]
    }
   ],
   "source": [
    "# get dataframes from CSV files\n",
    "\n",
    "df_occ_n_skills = pd.read_csv('../data/ESCO/occupations_augmented_with_skills.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87169c10",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filter unneeded columns of of the dataframe and add needed ones\n",
    "\n",
    "df_occ_n_skills = df_occ_n_skills.filter(items=['preferredLabel', 'description', 'skills'])\n",
    "df_occ_n_skills = df_occ_n_skills.reindex(columns=['preferredLabel','description', 'skills'])\n",
    "df_occ_n_skills.rename(columns={'preferredLabel': 'job_title'}, inplace=True)\n",
    "df_occ_n_skills['description_input'] = 0\n",
    "df_occ_n_skills['skills_input'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24a5345",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35824it [00:04, 7498.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# create description_input and skills_input, which are strings on which the model will be fit\n",
    "\n",
    "for row, index in tqdm(df_occ_n_skills.iterrows()):\n",
    "    underscored_job_title = index['job_title'].replace(\" \", \"_\")\n",
    "    this_rows_description_input = underscored_job_title + ' ' + index['description']\n",
    "    this_rows_skills_input = underscored_job_title + ' ' + index['skills']\n",
    "    df_occ_n_skills.iloc[row,-2] = this_rows_description_input\n",
    "    df_occ_n_skills.iloc[row,-1] = this_rows_skills_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3e40f6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>description</th>\n",
       "      <th>skills</th>\n",
       "      <th>description_input</th>\n",
       "      <th>skills_input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>technical director</td>\n",
       "      <td>Technical directors realise the artistic visio...</td>\n",
       "      <td>adapt to artists' creative demands, organise r...</td>\n",
       "      <td>technical_director Technical directors realise...</td>\n",
       "      <td>technical_director adapt to artists' creative ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>metal drawing machine operator</td>\n",
       "      <td>Metal drawing machine operators set up and ope...</td>\n",
       "      <td>cold drawing processes, monitor moving workpie...</td>\n",
       "      <td>metal_drawing_machine_operator Metal drawing m...</td>\n",
       "      <td>metal_drawing_machine_operator cold drawing pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>precision device inspector</td>\n",
       "      <td>Precision device inspectors make sure precisio...</td>\n",
       "      <td>precision measuring instruments, monitor machi...</td>\n",
       "      <td>precision_device_inspector Precision device in...</td>\n",
       "      <td>precision_device_inspector precision measuring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air traffic safety technician</td>\n",
       "      <td>Air traffic safety technicians provide technic...</td>\n",
       "      <td>air transport law, aircraft flight control sys...</td>\n",
       "      <td>air_traffic_safety_technician Air traffic safe...</td>\n",
       "      <td>air_traffic_safety_technician air transport la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hospitality revenue manager</td>\n",
       "      <td>Hospitality revenue managers maximise revenue ...</td>\n",
       "      <td>develop revenue generation strategies, ensure ...</td>\n",
       "      <td>hospitality_revenue_manager Hospitality revenu...</td>\n",
       "      <td>hospitality_revenue_manager develop revenue ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        job_title  \\\n",
       "0              technical director   \n",
       "1  metal drawing machine operator   \n",
       "2      precision device inspector   \n",
       "3   air traffic safety technician   \n",
       "4     hospitality revenue manager   \n",
       "\n",
       "                                         description  \\\n",
       "0  Technical directors realise the artistic visio...   \n",
       "1  Metal drawing machine operators set up and ope...   \n",
       "2  Precision device inspectors make sure precisio...   \n",
       "3  Air traffic safety technicians provide technic...   \n",
       "4  Hospitality revenue managers maximise revenue ...   \n",
       "\n",
       "                                              skills  \\\n",
       "0  adapt to artists' creative demands, organise r...   \n",
       "1  cold drawing processes, monitor moving workpie...   \n",
       "2  precision measuring instruments, monitor machi...   \n",
       "3  air transport law, aircraft flight control sys...   \n",
       "4  develop revenue generation strategies, ensure ...   \n",
       "\n",
       "                                   description_input  \\\n",
       "0  technical_director Technical directors realise...   \n",
       "1  metal_drawing_machine_operator Metal drawing m...   \n",
       "2  precision_device_inspector Precision device in...   \n",
       "3  air_traffic_safety_technician Air traffic safe...   \n",
       "4  hospitality_revenue_manager Hospitality revenu...   \n",
       "\n",
       "                                        skills_input  \n",
       "0  technical_director adapt to artists' creative ...  \n",
       "1  metal_drawing_machine_operator cold drawing pr...  \n",
       "2  precision_device_inspector precision measuring...  \n",
       "3  air_traffic_safety_technician air transport la...  \n",
       "4  hospitality_revenue_manager develop revenue ge...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect dataframe\n",
    "\n",
    "df_occ_n_skills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e56f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get entire dataframe as dataset according to Qiewi's suggestion\n",
    "# concatenate the job_title:skills list to the end of df_occ_n_skills\n",
    "\n",
    "X_all = pd.concat([df_occ_n_skills['description_input'], df_occ_n_skills['skills_input']]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f64558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying preprocessing to corpus as in Gensim tutorial, also applying Phraser\n",
    "\n",
    "def read_corpus(corpus):\n",
    "   \n",
    "    # instantiate Phraser outside of the loop\n",
    "    sentence_stream = [entry.split(\" \") for entry in corpus]\n",
    "    bigrams = Phrases(\n",
    "        sentence_stream,\n",
    "        min_count=5,\n",
    "        threshold=5,\n",
    "        connector_words=ENGLISH_CONNECTOR_WORDS\n",
    "        )\n",
    "    \n",
    "    for i, line in enumerate(corpus):    \n",
    "    \n",
    "        # remove punctuation\n",
    "        for punctuation in string.punctuation:        \n",
    "            sentence = line.replace(punctuation, '')\n",
    "\n",
    "        # remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = word_tokenize(sentence)\n",
    "        stopword_free_tokens = [token for token in tokens if token not in stop_words]\n",
    "        sentence = ' '.join(stopword_free_tokens)\n",
    "\n",
    "        # lemmatize\n",
    "        sentence = WordNetLemmatizer().lemmatize(sentence, pos='n')\n",
    "        sentence = WordNetLemmatizer().lemmatize(sentence, pos='v')\n",
    "        \n",
    "        # get bigrams\n",
    "        sent = sentence.split()\n",
    "\n",
    "        # yield tagged final corpus\n",
    "        yield TaggedDocument(bigrams[sent], [i])\n",
    "\n",
    "all_corpus = list(read_corpus(X_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f418ae61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'identify customer requirements identify potential markets for companies respond to enquiries identify market niches carry out strategic research analyse external factors of companies use different communication channels plan marketing strategy integrate marketing strategies with the global strategy analyse internal factors of companies use theoretical marketing models maintain relationship with customers conduct research interview define technical requirements market analysis marketing principles marketing mix advertising techniques social media management web strategy assessment channel marketing online ads campaign techniques brand marketing techniques e-commerce systems customer service social media marketing techniques perform business research support managers draft corporate emails manage the handling of promotional materials assist in developing marketing campaigns prepare presentation material marketing management marketing department processes collaborate in the development of marketing strategies persuade clients with alternatives liaise with advertising agencies conduct mobile marketing execute email marketing execute conversion testing implement marketing strategies use content management system software use different communication channels develop inclusive communication material plan marketing campaigns manage brand assets select optimal distribution channel perform brand analysis perform market research stimulate creativity in the team coordinate advertising campaigns'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "522a0c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function for job descriptions\n",
    "\n",
    "def preprocess_input(sentence, ds_insert=False, ds_insert_ratio=0.2):\n",
    "    \n",
    "    if ds_insert == True:\n",
    "        \n",
    "        sentence_splitted = sentence.split()\n",
    "        \n",
    "        insertion_amount = len(sentence_splitted)\n",
    "\n",
    "        for insertion in range(insertion_amount):\n",
    "            sentence_splitted.append(ds_skills[insertion])\n",
    "            \n",
    "        sentence = ' '.join(sentence_splitted)   \n",
    "    \n",
    "    # remove punctuation\n",
    "    for punctuation in string.punctuation:        \n",
    "        sentence = sentence.replace(punctuation, '')\n",
    "    \n",
    "    # set lowercase\n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    # remove numbers\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit())\n",
    "    \n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(sentence)\n",
    "    stopword_free_tokens = [token for token in tokens if token not in stop_words]\n",
    "    sentence = ' '.join(stopword_free_tokens)\n",
    "\n",
    "    # lemmatize\n",
    "    sentence = WordNetLemmatizer().lemmatize(sentence, pos='n')\n",
    "    sentence = WordNetLemmatizer().lemmatize(sentence, pos='v')\n",
    "    \n",
    "    # split into tokens again after Lemmatizing --- this was replaced by Phraser \n",
    "    # sentence = word_tokenize(sentence)\n",
    "    \n",
    "    # insert data science keywords if ds_insert==True\n",
    "    \n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b02b7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc70ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_description = preprocess_input(describe_your_job,ds_insert=True)\n",
    "# new_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f406fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ftraverso/code/francescotraverso/job_predictor/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c279c2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " all_corpus_embed_22.sav\t\t'francesco -  scratch notebook.ipynb'\r\n",
      " bert_model_22.sav\t\t\t function_join.ipynb\r\n",
      " CSV_enhancer.ipynb\t\t\t Local_API_extractor_fran.ipynb\r\n",
      " CV_FeatureExtractor_AllCVs.ipynb\t Local_API_extractor.ipynb\r\n",
      "'CV_FeatureExtractor_Cv Example.ipynb'\t model_DS_flare.ipynb\r\n",
      " doc2vec_exploration_fran.ipynb\t\t model_tuning_fran_3.ipynb\r\n",
      " ESCO_exploration.ipynb\t\t\t testing.ipynb\r\n",
      " ESCO_exploration_latest_fran.ipynb\t working_model_fran.ipynb\r\n",
      " ESCO_exploration_latest.ipynb\t\t working_model.ipynb\r\n",
      " feature_extractor_fran.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcf27b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "272d934b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch._C._nn'; 'torch._C' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load saved BERT model and its embedding from disk\u001b[39;00m\n\u001b[1;32m      3\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../model/bert_model.sav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.../model/all_corpus_embed.sav\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m all_corpus_embed \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._C._nn'; 'torch._C' is not a package"
     ]
    }
   ],
   "source": [
    "# load saved BERT model and its embedding from disk\n",
    "\n",
    "filename = '../model/bert_model.sav'\n",
    "bert_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "filename = '.../model/all_corpus_embed.sav'\n",
    "all_corpus_embed = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53650fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model\n",
    "\n",
    "# run input through the model\n",
    "new_description_embed = bert_model.encode(new_description)\n",
    "\n",
    "# calculate and order cosine similarity\n",
    "similarity_rank = cosine_similarity([new_description_embed], all_corpus_embed)\n",
    "similarity_rank_index = np.argsort(similarity_rank[0])[::-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff668e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### result comparison between no DS keywords and DS keywords ###\n",
    "\n",
    "# insert the ratio you want for the insertion of data science keywords (value between 0 and 1)\n",
    "ds_ratio = 0.1\n",
    "\n",
    "# preprocess\n",
    "new_description_no_ds = preprocess_input(describe_your_job)\n",
    "new_description_w_ds = preprocess_input(describe_your_job, ds_insert=True, ds_insert_ratio=ds_ratio)\n",
    "\n",
    "print(new_description_no_ds)\n",
    "print(new_description_w_ds)\n",
    "\n",
    "\n",
    "# run input through the model\n",
    "new_description_no_ds_embed = bert_model.encode(new_description_no_ds)\n",
    "new_description_w_ds_embed = bert_model.encode(new_description_w_ds)\n",
    "\n",
    "# calculate and order cosine similarity\n",
    "similarity_rank_no_ds = cosine_similarity([new_description_no_ds_embed], all_corpus_embed)\n",
    "similarity_rank_index_no_ds = np.argsort(similarity_rank_no_ds[0])[::-1]\n",
    "similarity_rank_w_ds = cosine_similarity([new_description_w_ds_embed], all_corpus_embed)\n",
    "similarity_rank_index_w_ds = np.argsort(similarity_rank_w_ds[0])[::-1]\n",
    "\n",
    "# show results\n",
    "print('~~~RESULT COMPARISON~~~ \\n')\n",
    "\n",
    "for i in range(n_jobs):\n",
    "    \n",
    "    if similarity_rank_index_no_ds[i] <= len(df_occ_n_skills):\n",
    "        new_index = similarity_rank_index_no_ds[i]\n",
    "    else:\n",
    "        new_index = similarity_rank_index_no_ds[i] - len(df_occ_n_skills)\n",
    "\n",
    "    print(f'RANK #{i+1}:')\n",
    "    print('ORIGINAL: ' + df_occ_n_skills.loc[new_index]['job_title'])\n",
    "\n",
    "    if similarity_rank_index_w_ds[i] <= len(df_occ_n_skills):\n",
    "        new_index = similarity_rank_index_w_ds[i]\n",
    "    else:\n",
    "        new_index = similarity_rank_index_w_ds[i] - len(df_occ_n_skills)\n",
    "    \n",
    "    print('W/ DS KW: ' + df_occ_n_skills.loc[new_index]['job_title'])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'TEST DOCUMENT: {new_description} \\n')\n",
    "print('LISTING 10 MOST SIMILAR JOB ROLES & DESCRIPTIONS \\n')\n",
    "\n",
    "for i in range(n_jobs):\n",
    "    \n",
    "    if similarity_rank_index[i] <= len(df_occ_n_skills):\n",
    "        new_index = similarity_rank_index[i]\n",
    "    else:\n",
    "        new_index = similarity_rank_index[i] - len(df_occ_n_skills)\n",
    "\n",
    "    print(f'RANK #{i+1}: ' + df_occ_n_skills.loc[new_index]['job_title'])\n",
    "    print(df_occ_n_skills.loc[new_index]['description'])\n",
    "    print(f'Similarity score: {round(similarity_rank[0][similarity_rank_index[i]]*100,1)} %')\n",
    "    print(f'Index in dataframe: {new_index} \\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc296e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc496e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
